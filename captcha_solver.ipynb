{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32577658-b040-4655-b4b0-b54c241a8a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d612340d-2adb-476b-937f-8e3b974774c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def preprocess_captcha(image_path, character_color):\n",
    "    # Load the captcha image\n",
    "    captcha = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(captcha, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a mask for the character color region\n",
    "    mask = cv2.inRange(gray, character_color, character_color)\n",
    "\n",
    "    # Set the character region to black\n",
    "    captcha[mask > 0] = (0, 0, 0)  # Set all channels to black (0, 0, 0)\n",
    "\n",
    "    # Set the background region to white\n",
    "    captcha[mask == 0] = (255, 255, 255)  # Set all channels to white (255, 255, 255)\n",
    "\n",
    "    return captcha\n",
    "\n",
    "# Example usage\n",
    "image_path = 'captchas/bdHBnp.png'\n",
    "character_color = 102  # Adjust this value to match the character color (hex: #666666)\n",
    "\n",
    "result = preprocess_captcha(image_path, character_color)\n",
    "\n",
    "# Display the preprocessed image\n",
    "cv2.imshow(\"Preprocessed Image\", result)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf670b-4211-4584-aded-7ebd94cb273f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9017a1-0417-4ce4-b3fb-ddcdbf024f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2af8908-d385-4e12-ae56-271af1692322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "l\n",
      "o\n",
      "q\n",
      "I\n",
      "O\n",
      "Q\n",
      "0\n",
      "1\n",
      "I guess these characters never appear, as it is ambiguous\n"
     ]
    }
   ],
   "source": [
    "# To make sure that i have collected all the characters.\n",
    "import os\n",
    "\n",
    "chars = {}\n",
    "letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for i in letters:\n",
    "    chars[i] = 0\n",
    "\n",
    "for i in letters.upper():\n",
    "    chars[i] = 0\n",
    "\n",
    "for i in range(10):\n",
    "    chars[str(i)] = 0\n",
    "\n",
    "image_names = os.listdir(\"./captchas\")\n",
    "\n",
    "for image_name in image_names:\n",
    "    characters = image_name[:-4]\n",
    "    if len(characters)==6:\n",
    "        for c in characters:\n",
    "            chars[c] += 1\n",
    "\n",
    "for i in chars:\n",
    "    if chars[i]==0:\n",
    "        print(i)\n",
    "\n",
    "print(\"I guess these characters never appear, as it is ambiguous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9209c7-6b32-4673-a694-d6242339128b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332cfeb-1a4a-4cda-a43d-6cb0fb748388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecf2e9-3830-4247-b166-01a2e048eac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801b532e-aabb-4d18-940e-7979488d341f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\".find(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4d737-cdcc-4c5d-9e1f-52cb97482fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd7f25c-ceeb-4454-aaef-c91cc706e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 158, 73, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 79, 36, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 77, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41344)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               5292160   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,311,750\n",
      "Trainable params: 5,311,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the input shape of your captcha images\n",
    "input_shape = (160, 75, 1)  # Assuming grayscale captcha images, adjust the channel value if using RGB images\n",
    "\n",
    "# Define the character set\n",
    "characters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "num_characters = len(characters)\n",
    "\n",
    "# Define the maximum length of the captcha sequence\n",
    "max_sequence_length = 6\n",
    "\n",
    "# Define the scale factor for mapping output values to the desired range\n",
    "scale_factor = num_characters - 1  # Scale factor to map values from 0 to 1 to the range of 0 to num_characters-1\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(max_sequence_length, activation='relu')\n",
    "])\n",
    "\n",
    "# Scale the output values to the desired range\n",
    "model.add(layers.Lambda(lambda x: scale_factor * tf.nn.relu(x)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1e143-627e-42a5-b323-af4573b6db94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b2fa3-7c3b-4609-8401-8a03588b536f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bfda3c9e-ba6e-4fbe-aee8-049f0a4dac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation with preprocessing images\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the paths for the input and output directories\n",
    "input_dir = './captchas'\n",
    "output_dir = './preprocessed_captchas'\n",
    "\n",
    "# Set up the data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Random rotation between -10 and +10 degrees\n",
    "    width_shift_range=0.1,  # Random horizontal shift by 10% of the image width\n",
    "    height_shift_range=0.1,  # Random vertical shift by 10% of the image height\n",
    "    shear_range=0.2,  # Apply shear transformation with a maximum shear of 20%\n",
    "    zoom_range=0.2,  # Randomly zoom in or out by 20%\n",
    "    fill_mode='constant',  # Fill any empty pixels with constant value (e.g., black)\n",
    "    cval=255  # Set the constant value to white (255)\n",
    ")\n",
    "\n",
    "# Iterate over the images in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    # Read the image\n",
    "    image_path = os.path.join(input_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    preprocessed_image = preprocess_captcha(image_path, character_color)\n",
    "    \n",
    "    # Expand dimensions to match the expected input shape of the model\n",
    "    # preprocessed_image = np.expand_dims(preprocessed_image, axis=-1)\n",
    "    \n",
    "    # Create a directory for the current image in the output directory\n",
    "    output_subdir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "    if not os.path.exists(output_subdir):\n",
    "        os.makedirs(output_subdir)\n",
    "    \n",
    "    # Generate augmented images and save them in the output directory\n",
    "    for i, batch in enumerate(datagen.flow(np.array([preprocessed_image]), batch_size=1)):\n",
    "        augmented_image = batch[0].astype(np.uint8)\n",
    "        \n",
    "        # Save the augmented image\n",
    "        output_filename = f'{os.path.splitext(filename)[0]}_{i}.png'\n",
    "        output_path = os.path.join(output_subdir, output_filename)\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "        \n",
    "        # Break the loop after generating a desired number of augmented images\n",
    "        if i == 99:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d04d6-c34f-408a-83c2-e04d4366efda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f03fd-db16-4a89-ad4a-a05f14e68435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0c275c8-1cad-4fe7-9230-ec7ac2e14c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 158, 73, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 79, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 77, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 38, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 41344)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               5292160   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 372)               47988     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 6, 62)             0         \n",
      "                                                                 \n",
      " lambda_3 (Lambda)           (None, 6, 62)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,358,964\n",
      "Trainable params: 5,358,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the input shape of your captcha images\n",
    "input_shape = (160, 75, 1)  # Assuming grayscale captcha images, adjust the channel value if using RGB images\n",
    "\n",
    "# Define the character set\n",
    "characters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "num_characters = len(characters)\n",
    "\n",
    "# Define the maximum length of the captcha sequence\n",
    "max_sequence_length = 6\n",
    "\n",
    "# Define the scale factor for mapping output values to the desired range\n",
    "scale_factor = num_characters - 1  # Scale factor to map values from 0 to 1 to the range of 0 to num_characters-1\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(max_sequence_length * num_characters, activation='relu'),\n",
    "    layers.Reshape((max_sequence_length, num_characters))\n",
    "])\n",
    "\n",
    "# Scale the output values to the desired range\n",
    "model.add(layers.Lambda(lambda x: scale_factor * tf.nn.relu(x)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f137c-4484-4811-99f5-7cbd348b015a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "061adb84-ca99-444b-9a27-54d205e7ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the paths for the preprocessed images\n",
    "images_dir = 'preprocessed_captchas'\n",
    "\n",
    "\n",
    "# Define the characters for mapping labels\n",
    "characters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "\n",
    "# Function to convert labels to list form\n",
    "def convert_label_to_list(label):\n",
    "    label_list = []\n",
    "    for char in label:\n",
    "        index = characters.index(char)\n",
    "        oh = [0]*62\n",
    "        oh[index] = 1\n",
    "        label_list.append(oh)\n",
    "    return label_list\n",
    "\n",
    "# Load the preprocessed images and labels\n",
    "X = []\n",
    "y = []\n",
    "for subdir, dirs, files in os.walk(images_dir):\n",
    "    for file in files:\n",
    "        # Load the image\n",
    "        image_path = os.path.join(subdir, file)\n",
    "        image = keras.preprocessing.image.load_img(image_path, color_mode='grayscale', target_size=input_shape[:2])\n",
    "        image = keras.preprocessing.image.img_to_array(image)\n",
    "        image /= 255.0\n",
    "        X.append(image)\n",
    "        \n",
    "        # Extract the label from the file name\n",
    "        label = file.split('.')[0][:6]\n",
    "        label_list = convert_label_to_list(label)\n",
    "        y.append(label_list)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ff9346b-b37b-4a9d-af5c-d88a4b8bee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "validation_split = 0.2\n",
    "split_index = int(len(X) * (1 - validation_split))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "num_classes = len(characters)\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0fc8ff9-5f10-4c67-8851-a1c147c83ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010, 160, 75, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f0d414ee-7684-4a85-a1cc-96709e7c8f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010, 6, 62)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76582e1e-009e-42e2-b05e-cafbfe6b17d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4010, 6, 62)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1b7920e7-7b1d-4cfd-ab29-e345535b8c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003, 6, 62)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "479b678e-df2e-4da1-b869-e74232a92998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 6, 62)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ecf2e429-5cd6-4809-b365-847f67d3d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"  # Specify the directory path for logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c09aedd-a199-495a-a53e-66f13df73435",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e101e6ab-eb9f-4328-858b-96104879dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"D:\\anaconda\\envs\\captcha\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\anaconda\\envs\\captcha\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Lakshman Kishore\\AppData\\Local\\Temp\\ipykernel_20848\\1240435430.py\", line 1, in <module>\n      model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[tensorboard_callback])\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [192,62] and labels shape [11904]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_23069]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4010\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m62\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m62\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\captcha\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"D:\\anaconda\\envs\\captcha\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\anaconda\\envs\\captcha\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Lakshman Kishore\\AppData\\Local\\Temp\\ipykernel_20848\\1240435430.py\", line 1, in <module>\n      model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[tensorboard_callback])\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"D:\\anaconda\\envs\\captcha\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [192,62] and labels shape [11904]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_23069]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train.reshape(4010,6,62), batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val.reshape(1003,6,62)), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eab8b1c-4603-45d5-ac0c-28824436e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard is running at http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import program\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, '--logdir', log_dir])\n",
    "url = tb.launch()\n",
    "print(f\"TensorBoard is running at {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f61a099-5b12-4d32-a972-6d9651f732de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3174b-89a9-4d28-a4cb-021ef12fb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689da95-0745-478e-99c7-4e93c9e8a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72faebf-a6e8-435b-bfe4-4436495d70d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir \\\n",
    "    'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2b13f16-c514-48ad-92a7-5b674d8119f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90f787c3-be93-4fc2-9bd6-a8d8a81269b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only allocate a specific amount of GPU memory\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd3a0f7c-dc27-4a88-9c80-a5c5332709a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790f2f9-7000-4735-89ee-93ed0cd0cb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "814977f1-4c90-4b0e-8011-53415c757737",
   "metadata": {},
   "outputs": [],
   "source": [
    "timage = keras.preprocessing.image.load_img(\"./preprocessed_captchas/8sxnXu/8sxnXu_1.png\", color_mode='grayscale', target_size=input_shape[:2])\n",
    "timage = keras.preprocessing.image.img_to_array(timage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4903852d-136d-4cc2-84b7-82e67b1026c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timage/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "11435754-79ea-44d9-b7a1-c9a67742c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timage = np.array(timage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f4b5c917-3856-4120-a6cf-b8eb1971471f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 75, 1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2304b9ad-b6ca-42c5-bcd6-d60073813957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 75, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "66fd5d46-c330-485a-8a3c-1aa4bb9a1bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 160, 3)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "74f08fa9-887c-4d70-b098-3ad7cc561516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 75, 1)\n"
     ]
    }
   ],
   "source": [
    "image = keras.preprocessing.image.load_img(\"./preprocessed_captchas/HuayFn/HuayFn_1.png\", color_mode='grayscale', target_size=input_shape[:2])\n",
    "image = keras.preprocessing.image.img_to_array(image)\n",
    "image /= 255.0\n",
    "\n",
    "print(image.shape)\n",
    "image = np.array([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "39db5798-31fa-4916-bcd3-b130de027c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b53147f9-853e-4a63-991f-f40b3af9f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 62)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f21d21d2-6e90-424b-bc23-aa402f1596c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'u', 'a', 'y', 'F', 'n']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = tf.argmax(tf.squeeze(predictions), axis=-1)\n",
    "\n",
    "# Convert the predicted labels to characters\n",
    "characters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "predicted_characters = [characters[label] for label in predicted_labels]\n",
    "\n",
    "# Print the predicted characters\n",
    "print(predicted_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ddc5799d-e257-48ed-b7b1-c31283518848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 0, 30, 10, 34, 41, 23], dtype=int64)>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a15e4c9e-deb9-4c57-b42b-e700754ad049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "574d8be1-15f1-494c-8070-c5beba37b542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 62)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "555e0a3f-35be-46b0-8b20-56fe1bf909ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([10,  7, 43, 29, 40, 36], dtype=int64)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(predictions[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896d0a6-64f9-41ec-b5e0-e02b77574948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96786a84-64d3-437a-8a0e-64ee5da945c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captcha",
   "language": "python",
   "name": "captcha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
